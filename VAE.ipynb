{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyjet import cluster,DTYPE_PTEPM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = path = '/anomalyvol/data/events_LHCO2020_backgroundMC_Pythia.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2090</th>\n",
       "      <th>2091</th>\n",
       "      <th>2092</th>\n",
       "      <th>2093</th>\n",
       "      <th>2094</th>\n",
       "      <th>2095</th>\n",
       "      <th>2096</th>\n",
       "      <th>2097</th>\n",
       "      <th>2098</th>\n",
       "      <th>2099</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.587869</td>\n",
       "      <td>-2.323472</td>\n",
       "      <td>-2.597121</td>\n",
       "      <td>1.497173</td>\n",
       "      <td>-2.480994</td>\n",
       "      <td>-2.269457</td>\n",
       "      <td>0.848844</td>\n",
       "      <td>-2.465643</td>\n",
       "      <td>-2.096595</td>\n",
       "      <td>0.961511</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.921213</td>\n",
       "      <td>-0.745233</td>\n",
       "      <td>1.018857</td>\n",
       "      <td>0.689363</td>\n",
       "      <td>-0.642245</td>\n",
       "      <td>3.050711</td>\n",
       "      <td>1.999174</td>\n",
       "      <td>-0.343135</td>\n",
       "      <td>-0.322586</td>\n",
       "      <td>1.580572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.580352</td>\n",
       "      <td>-2.412026</td>\n",
       "      <td>1.680236</td>\n",
       "      <td>0.429869</td>\n",
       "      <td>-0.778697</td>\n",
       "      <td>-1.453413</td>\n",
       "      <td>0.856914</td>\n",
       "      <td>-2.243512</td>\n",
       "      <td>0.217628</td>\n",
       "      <td>0.407344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.579134</td>\n",
       "      <td>-0.243543</td>\n",
       "      <td>-2.561824</td>\n",
       "      <td>0.312690</td>\n",
       "      <td>-0.283086</td>\n",
       "      <td>-0.281626</td>\n",
       "      <td>0.775053</td>\n",
       "      <td>-2.062494</td>\n",
       "      <td>-1.598718</td>\n",
       "      <td>0.868891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.644219</td>\n",
       "      <td>-2.457281</td>\n",
       "      <td>-2.670996</td>\n",
       "      <td>0.186128</td>\n",
       "      <td>-1.757650</td>\n",
       "      <td>2.719159</td>\n",
       "      <td>0.346987</td>\n",
       "      <td>-2.318233</td>\n",
       "      <td>-0.155036</td>\n",
       "      <td>0.501437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.493004</td>\n",
       "      <td>-0.886976</td>\n",
       "      <td>-0.391002</td>\n",
       "      <td>0.534181</td>\n",
       "      <td>-2.081904</td>\n",
       "      <td>2.548825</td>\n",
       "      <td>0.458036</td>\n",
       "      <td>-1.230976</td>\n",
       "      <td>2.204294</td>\n",
       "      <td>0.639672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.404833</td>\n",
       "      <td>-0.510012</td>\n",
       "      <td>2.969482</td>\n",
       "      <td>0.300500</td>\n",
       "      <td>-2.248194</td>\n",
       "      <td>1.012964</td>\n",
       "      <td>0.316375</td>\n",
       "      <td>-1.815956</td>\n",
       "      <td>1.011110</td>\n",
       "      <td>0.604675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.407082</td>\n",
       "      <td>-2.195407</td>\n",
       "      <td>2.632497</td>\n",
       "      <td>0.413497</td>\n",
       "      <td>-1.212703</td>\n",
       "      <td>2.704103</td>\n",
       "      <td>0.578276</td>\n",
       "      <td>-0.291654</td>\n",
       "      <td>1.065150</td>\n",
       "      <td>0.508287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.573155</td>\n",
       "      <td>-0.755578</td>\n",
       "      <td>0.347725</td>\n",
       "      <td>0.751455</td>\n",
       "      <td>-1.929361</td>\n",
       "      <td>0.759764</td>\n",
       "      <td>0.798534</td>\n",
       "      <td>-0.532149</td>\n",
       "      <td>0.979545</td>\n",
       "      <td>0.941284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.481400</td>\n",
       "      <td>-1.687436</td>\n",
       "      <td>-1.485912</td>\n",
       "      <td>0.560682</td>\n",
       "      <td>-0.641398</td>\n",
       "      <td>1.572734</td>\n",
       "      <td>1.772811</td>\n",
       "      <td>-1.698486</td>\n",
       "      <td>-0.681214</td>\n",
       "      <td>3.826682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6     \\\n",
       "0    3.587869 -2.323472 -2.597121  1.497173 -2.480994 -2.269457  0.848844   \n",
       "1    0.921213 -0.745233  1.018857  0.689363 -0.642245  3.050711  1.999174   \n",
       "2    0.580352 -2.412026  1.680236  0.429869 -0.778697 -1.453413  0.856914   \n",
       "3    0.579134 -0.243543 -2.561824  0.312690 -0.283086 -0.281626  0.775053   \n",
       "4    0.644219 -2.457281 -2.670996  0.186128 -1.757650  2.719159  0.346987   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "995  0.493004 -0.886976 -0.391002  0.534181 -2.081904  2.548825  0.458036   \n",
       "996  0.404833 -0.510012  2.969482  0.300500 -2.248194  1.012964  0.316375   \n",
       "997  0.407082 -2.195407  2.632497  0.413497 -1.212703  2.704103  0.578276   \n",
       "998  0.573155 -0.755578  0.347725  0.751455 -1.929361  0.759764  0.798534   \n",
       "999  0.481400 -1.687436 -1.485912  0.560682 -0.641398  1.572734  1.772811   \n",
       "\n",
       "         7         8         9     ...  2090  2091  2092  2093  2094  2095  \\\n",
       "0   -2.465643 -2.096595  0.961511  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "1   -0.343135 -0.322586  1.580572  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2   -2.243512  0.217628  0.407344  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "3   -2.062494 -1.598718  0.868891  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "4   -2.318233 -0.155036  0.501437  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "..        ...       ...       ...  ...   ...   ...   ...   ...   ...   ...   \n",
       "995 -1.230976  2.204294  0.639672  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "996 -1.815956  1.011110  0.604675  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "997 -0.291654  1.065150  0.508287  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "998 -0.532149  0.979545  0.941284  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "999 -1.698486 -0.681214  3.826682  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "     2096  2097  2098  2099  \n",
       "0     0.0   0.0   0.0   0.0  \n",
       "1     0.0   0.0   0.0   0.0  \n",
       "2     0.0   0.0   0.0   0.0  \n",
       "3     0.0   0.0   0.0   0.0  \n",
       "4     0.0   0.0   0.0   0.0  \n",
       "..    ...   ...   ...   ...  \n",
       "995   0.0   0.0   0.0   0.0  \n",
       "996   0.0   0.0   0.0   0.0  \n",
       "997   0.0   0.0   0.0   0.0  \n",
       "998   0.0   0.0   0.0   0.0  \n",
       "999   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[1000 rows x 2100 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_hdf(path,stop=1000) # just read first 1000 events\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_events = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = all_events.shape[0]\n",
    "cols = all_events.shape[1]\n",
    "data = np.zeros((rows, cols // 3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(rows):\n",
    "    pseudojets_input = np.zeros(len([x for x in all_events[i][::3] if x > 0]), dtype=DTYPE_PTEPM)\n",
    "    for j in range(cols // 3):\n",
    "        if (all_events[i][j*3]>0):\n",
    "            pseudojets_input[j]['pT'] = all_events[i][j*3]\n",
    "            pseudojets_input[j]['eta'] = all_events[i][j*3+1]\n",
    "            pseudojets_input[j]['phi'] = all_events[i][j*3+2]\n",
    "        pass\n",
    "    sequence = cluster(pseudojets_input, R=1.0, p=-1)\n",
    "    jets = sequence.inclusive_jets()\n",
    "    for k in range(len(jets)):\n",
    "        data[i][k][0] = jets[k].pt\n",
    "        data[i][k][1] = jets[k].eta\n",
    "        data[i][k][2] = jets[k].phi\n",
    "        data[i][k][3] = jets[k].mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 700, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Lambda, Input, Dense, Flatten, Reshape\n",
    "from keras.models import Model, Sequential\n",
    "from keras import metrics\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    \"\"\"\n",
    "    # Arguments\n",
    "        args (tensor): mean and log of variance of Q(z|X)\n",
    "    # Returns\n",
    "        z (tensor): sampled latent vector\n",
    "    \"\"\"\n",
    "\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean = 0 and std = 1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_dim = 32\n",
    "final_dim = 8\n",
    "latent_dim = 2\n",
    "input_shape = (cols // 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder\n",
    "x = Input(shape=input_shape)\n",
    "x_flat = Flatten()(x)\n",
    "h1 = Dense(inter_dim, activation='relu')(x_flat)\n",
    "h2 = Dense(final_dim, activation='relu')(h1)\n",
    "z_mean = Dense(latent_dim)(h2)\n",
    "z_log_sigma = Dense(latent_dim)(h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random sampling\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])\n",
    "\n",
    "encoder = Model(inputs = x, outputs = z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder\n",
    "decoder_h2 = Dense(final_dim, activation='relu')\n",
    "decoder_h1 = Dense(inter_dim, activation='relu')\n",
    "decoder_mean = Dense(np.prod(input_shape), activation='sigmoid')\n",
    "\n",
    "h2_decoded = decoder_h2(z)\n",
    "h1_decoded = decoder_h1(h2_decoded)\n",
    "x_decoded_mean = decoder_mean(h1_decoded)\n",
    "x_decoded = Reshape(input_shape)(x_decoded_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = Model(inputs = x, outputs = x_decoded, name = 'vae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(x, y):\n",
    "    xent_loss = metrics.binary_crossentropy(K.flatten(x), K.flatten(y))\n",
    "    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)\n",
    "    return xent_loss + kl_loss\n",
    "\n",
    "vae.compile(optimizer='adam', loss=vae_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vae\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 700, 4)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2800)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           89632       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 8)            264         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            18          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            18          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 2)            0           dense_3[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 8)            24          lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 32)           288         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 2800)         92400       dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 700, 4)       0           dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 182,644\n",
      "Trainable params: 182,644\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = data[0:int(len(data) * 0.8)]\n",
    "x_val = data[int(len(data) * 0.8):]\n",
    "batch_size = 100\n",
    "epochs = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 700, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/150\n",
      "800/800 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/150\n",
      "800/800 [==============================] - 0s 86us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/150\n",
      "800/800 [==============================] - 0s 89us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/150\n",
      "800/800 [==============================] - 0s 83us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/150\n",
      "800/800 [==============================] - 0s 81us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/150\n",
      "800/800 [==============================] - 0s 83us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/150\n",
      "800/800 [==============================] - 0s 84us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/150\n",
      "800/800 [==============================] - 0s 88us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/150\n",
      "800/800 [==============================] - 0s 86us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/150\n",
      "800/800 [==============================] - 0s 84us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/150\n",
      "800/800 [==============================] - 0s 88us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/150\n",
      "800/800 [==============================] - 0s 92us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/150\n",
      "800/800 [==============================] - 0s 79us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/150\n",
      "800/800 [==============================] - 0s 82us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/150\n",
      "800/800 [==============================] - 0s 90us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/150\n",
      "800/800 [==============================] - 0s 85us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/150\n",
      "800/800 [==============================] - 0s 84us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/150\n",
      "800/800 [==============================] - 0s 86us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/150\n",
      "800/800 [==============================] - 0s 85us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/150\n",
      "800/800 [==============================] - 0s 80us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/150\n",
      "800/800 [==============================] - 0s 82us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/150\n",
      "800/800 [==============================] - 0s 90us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/150\n",
      "800/800 [==============================] - 0s 87us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/150\n",
      "800/800 [==============================] - 0s 90us/step - loss: nan - val_loss: nan\n",
      "Epoch 25/150\n",
      "800/800 [==============================] - 0s 89us/step - loss: nan - val_loss: nan\n",
      "Epoch 26/150\n",
      "800/800 [==============================] - 0s 84us/step - loss: nan - val_loss: nan\n",
      "Epoch 27/150\n",
      "800/800 [==============================] - 0s 96us/step - loss: nan - val_loss: nan\n",
      "Epoch 28/150\n",
      "800/800 [==============================] - 0s 89us/step - loss: nan - val_loss: nan\n",
      "Epoch 29/150\n",
      "800/800 [==============================] - 0s 84us/step - loss: nan - val_loss: nan\n",
      "Epoch 30/150\n",
      "800/800 [==============================] - 0s 87us/step - loss: nan - val_loss: nan\n",
      "Epoch 31/150\n",
      "800/800 [==============================] - 0s 88us/step - loss: nan - val_loss: nan\n",
      "Epoch 32/150\n",
      "800/800 [==============================] - 0s 84us/step - loss: nan - val_loss: nan\n",
      "Epoch 33/150\n",
      "800/800 [==============================] - 0s 90us/step - loss: nan - val_loss: nan\n",
      "Epoch 34/150\n",
      "800/800 [==============================] - 0s 87us/step - loss: nan - val_loss: nan\n",
      "Epoch 35/150\n",
      "800/800 [==============================] - 0s 80us/step - loss: nan - val_loss: nan\n",
      "Epoch 36/150\n",
      "800/800 [==============================] - 0s 84us/step - loss: nan - val_loss: nan\n",
      "Epoch 37/150\n",
      "800/800 [==============================] - 0s 91us/step - loss: nan - val_loss: nan\n",
      "Epoch 38/150\n",
      "800/800 [==============================] - 0s 101us/step - loss: nan - val_loss: nan\n",
      "Epoch 39/150\n",
      "800/800 [==============================] - 0s 96us/step - loss: nan - val_loss: nan\n",
      "Epoch 40/150\n",
      "800/800 [==============================] - 0s 83us/step - loss: nan - val_loss: nan\n",
      "Epoch 41/150\n",
      "800/800 [==============================] - 0s 88us/step - loss: nan - val_loss: nan\n",
      "Epoch 42/150\n",
      "800/800 [==============================] - 0s 84us/step - loss: nan - val_loss: nan\n",
      "Epoch 43/150\n",
      "800/800 [==============================] - 0s 91us/step - loss: nan - val_loss: nan\n",
      "Epoch 44/150\n",
      "800/800 [==============================] - 0s 92us/step - loss: nan - val_loss: nan\n",
      "Epoch 45/150\n",
      "800/800 [==============================] - 0s 99us/step - loss: nan - val_loss: nan\n",
      "Epoch 46/150\n",
      "800/800 [==============================] - 0s 82us/step - loss: nan - val_loss: nan\n",
      "Epoch 47/150\n",
      "800/800 [==============================] - 0s 83us/step - loss: nan - val_loss: nan\n",
      "Epoch 48/150\n",
      "800/800 [==============================] - 0s 97us/step - loss: nan - val_loss: nan\n",
      "Epoch 49/150\n",
      "800/800 [==============================] - 0s 89us/step - loss: nan - val_loss: nan\n",
      "Epoch 50/150\n",
      "800/800 [==============================] - 0s 90us/step - loss: nan - val_loss: nan\n",
      "Epoch 51/150\n",
      "800/800 [==============================] - 0s 90us/step - loss: nan - val_loss: nan\n",
      "Epoch 52/150\n",
      "800/800 [==============================] - 0s 86us/step - loss: nan - val_loss: nan\n",
      "Epoch 53/150\n",
      "800/800 [==============================] - 0s 80us/step - loss: nan - val_loss: nan\n",
      "Epoch 54/150\n",
      "800/800 [==============================] - 0s 84us/step - loss: nan - val_loss: nan\n",
      "Epoch 55/150\n",
      "800/800 [==============================] - 0s 85us/step - loss: nan - val_loss: nan\n",
      "Epoch 56/150\n",
      "800/800 [==============================] - 0s 82us/step - loss: nan - val_loss: nan\n",
      "Epoch 57/150\n",
      "800/800 [==============================] - 0s 89us/step - loss: nan - val_loss: nan\n",
      "Epoch 58/150\n",
      "800/800 [==============================] - 0s 82us/step - loss: nan - val_loss: nan\n",
      "Epoch 59/150\n",
      "800/800 [==============================] - 0s 91us/step - loss: nan - val_loss: nan\n",
      "Epoch 60/150\n",
      "800/800 [==============================] - 0s 85us/step - loss: nan - val_loss: nan\n",
      "Epoch 61/150\n",
      "800/800 [==============================] - 0s 89us/step - loss: nan - val_loss: nan\n",
      "Epoch 62/150\n",
      "800/800 [==============================] - 0s 94us/step - loss: nan - val_loss: nan\n",
      "Epoch 63/150\n",
      "800/800 [==============================] - 0s 93us/step - loss: nan - val_loss: nan\n",
      "Epoch 64/150\n",
      "800/800 [==============================] - 0s 97us/step - loss: nan - val_loss: nan\n",
      "Epoch 65/150\n",
      "800/800 [==============================] - 0s 85us/step - loss: nan - val_loss: nan\n",
      "Epoch 66/150\n",
      "800/800 [==============================] - 0s 90us/step - loss: nan - val_loss: nan\n",
      "Epoch 67/150\n",
      "800/800 [==============================] - 0s 96us/step - loss: nan - val_loss: nan\n",
      "Epoch 68/150\n",
      "800/800 [==============================] - 0s 85us/step - loss: nan - val_loss: nan\n",
      "Epoch 69/150\n",
      "800/800 [==============================] - 0s 88us/step - loss: nan - val_loss: nan\n",
      "Epoch 70/150\n",
      "800/800 [==============================] - 0s 86us/step - loss: nan - val_loss: nan\n",
      "Epoch 71/150\n",
      "800/800 [==============================] - 0s 99us/step - loss: nan - val_loss: nan\n",
      "Epoch 72/150\n",
      "800/800 [==============================] - 0s 87us/step - loss: nan - val_loss: nan\n",
      "Epoch 73/150\n",
      "800/800 [==============================] - 0s 86us/step - loss: nan - val_loss: nan\n",
      "Epoch 74/150\n",
      "800/800 [==============================] - 0s 84us/step - loss: nan - val_loss: nan\n",
      "Epoch 75/150\n",
      "800/800 [==============================] - 0s 89us/step - loss: nan - val_loss: nan\n",
      "Epoch 76/150\n",
      "800/800 [==============================] - 0s 85us/step - loss: nan - val_loss: nan\n",
      "Epoch 77/150\n",
      "800/800 [==============================] - 0s 88us/step - loss: nan - val_loss: nan\n",
      "Epoch 78/150\n",
      "800/800 [==============================] - 0s 93us/step - loss: nan - val_loss: nan\n",
      "Epoch 79/150\n",
      "800/800 [==============================] - 0s 84us/step - loss: nan - val_loss: nan\n",
      "Epoch 80/150\n",
      "800/800 [==============================] - 0s 85us/step - loss: nan - val_loss: nan\n",
      "Epoch 81/150\n",
      "800/800 [==============================] - 0s 83us/step - loss: nan - val_loss: nan\n",
      "Epoch 82/150\n",
      "800/800 [==============================] - 0s 87us/step - loss: nan - val_loss: nan\n",
      "Epoch 83/150\n",
      "800/800 [==============================] - 0s 87us/step - loss: nan - val_loss: nan\n",
      "Epoch 84/150\n",
      "800/800 [==============================] - 0s 85us/step - loss: nan - val_loss: nan\n",
      "Epoch 85/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 87us/step - loss: nan - val_loss: nan\n",
      "Epoch 86/150\n",
      "800/800 [==============================] - 0s 83us/step - loss: nan - val_loss: nan\n",
      "Epoch 87/150\n",
      "800/800 [==============================] - 0s 85us/step - loss: nan - val_loss: nan\n",
      "Epoch 88/150\n",
      "800/800 [==============================] - 0s 83us/step - loss: nan - val_loss: nan\n",
      "Epoch 89/150\n",
      "800/800 [==============================] - 0s 91us/step - loss: nan - val_loss: nan\n",
      "Epoch 90/150\n",
      "800/800 [==============================] - 0s 97us/step - loss: nan - val_loss: nan\n",
      "Epoch 91/150\n",
      "800/800 [==============================] - 0s 87us/step - loss: nan - val_loss: nan\n",
      "Epoch 92/150\n",
      "800/800 [==============================] - 0s 85us/step - loss: nan - val_loss: nan\n",
      "Epoch 93/150\n",
      "800/800 [==============================] - 0s 91us/step - loss: nan - val_loss: nan\n",
      "Epoch 94/150\n",
      "800/800 [==============================] - 0s 92us/step - loss: nan - val_loss: nan\n",
      "Epoch 95/150\n",
      "800/800 [==============================] - 0s 87us/step - loss: nan - val_loss: nan\n",
      "Epoch 96/150\n",
      "800/800 [==============================] - 0s 86us/step - loss: nan - val_loss: nan\n",
      "Epoch 97/150\n",
      "800/800 [==============================] - 0s 91us/step - loss: nan - val_loss: nan\n",
      "Epoch 98/150\n",
      "800/800 [==============================] - 0s 88us/step - loss: nan - val_loss: nan\n",
      "Epoch 99/150\n",
      "800/800 [==============================] - 0s 89us/step - loss: nan - val_loss: nan\n",
      "Epoch 100/150\n",
      "800/800 [==============================] - 0s 84us/step - loss: nan - val_loss: nan\n",
      "Epoch 101/150\n",
      "800/800 [==============================] - 0s 88us/step - loss: nan - val_loss: nan\n",
      "Epoch 102/150\n",
      "800/800 [==============================] - 0s 88us/step - loss: nan - val_loss: nan\n",
      "Epoch 103/150\n",
      "800/800 [==============================] - 0s 86us/step - loss: nan - val_loss: nan\n",
      "Epoch 104/150\n",
      "800/800 [==============================] - 0s 88us/step - loss: nan - val_loss: nan\n",
      "Epoch 105/150\n",
      "800/800 [==============================] - 0s 91us/step - loss: nan - val_loss: nan\n",
      "Epoch 106/150\n",
      "800/800 [==============================] - 0s 97us/step - loss: nan - val_loss: nan\n",
      "Epoch 107/150\n",
      "800/800 [==============================] - 0s 88us/step - loss: nan - val_loss: nan\n",
      "Epoch 108/150\n",
      "800/800 [==============================] - 0s 87us/step - loss: nan - val_loss: nan\n",
      "Epoch 109/150\n",
      "800/800 [==============================] - 0s 89us/step - loss: nan - val_loss: nan\n",
      "Epoch 110/150\n",
      "800/800 [==============================] - 0s 92us/step - loss: nan - val_loss: nan\n",
      "Epoch 111/150\n",
      "800/800 [==============================] - 0s 83us/step - loss: nan - val_loss: nan\n",
      "Epoch 112/150\n",
      "800/800 [==============================] - 0s 81us/step - loss: nan - val_loss: nan\n",
      "Epoch 113/150\n",
      "800/800 [==============================] - 0s 80us/step - loss: nan - val_loss: nan\n",
      "Epoch 114/150\n",
      "800/800 [==============================] - 0s 81us/step - loss: nan - val_loss: nan\n",
      "Epoch 115/150\n",
      "800/800 [==============================] - 0s 80us/step - loss: nan - val_loss: nan\n",
      "Epoch 116/150\n",
      "800/800 [==============================] - 0s 79us/step - loss: nan - val_loss: nan\n",
      "Epoch 117/150\n",
      "800/800 [==============================] - 0s 78us/step - loss: nan - val_loss: nan\n",
      "Epoch 118/150\n",
      "800/800 [==============================] - 0s 81us/step - loss: nan - val_loss: nan\n",
      "Epoch 119/150\n",
      "800/800 [==============================] - 0s 82us/step - loss: nan - val_loss: nan\n",
      "Epoch 120/150\n",
      "800/800 [==============================] - 0s 87us/step - loss: nan - val_loss: nan\n",
      "Epoch 121/150\n",
      "800/800 [==============================] - 0s 88us/step - loss: nan - val_loss: nan\n",
      "Epoch 122/150\n",
      "800/800 [==============================] - 0s 89us/step - loss: nan - val_loss: nan\n",
      "Epoch 123/150\n",
      "800/800 [==============================] - 0s 92us/step - loss: nan - val_loss: nan\n",
      "Epoch 124/150\n",
      "800/800 [==============================] - 0s 98us/step - loss: nan - val_loss: nan\n",
      "Epoch 125/150\n",
      "800/800 [==============================] - 0s 96us/step - loss: nan - val_loss: nan\n",
      "Epoch 126/150\n",
      "800/800 [==============================] - 0s 90us/step - loss: nan - val_loss: nan\n",
      "Epoch 127/150\n",
      "800/800 [==============================] - 0s 91us/step - loss: nan - val_loss: nan\n",
      "Epoch 128/150\n",
      "800/800 [==============================] - 0s 89us/step - loss: nan - val_loss: nan\n",
      "Epoch 129/150\n",
      "800/800 [==============================] - 0s 85us/step - loss: nan - val_loss: nan\n",
      "Epoch 130/150\n",
      "800/800 [==============================] - 0s 85us/step - loss: nan - val_loss: nan\n",
      "Epoch 131/150\n",
      "800/800 [==============================] - 0s 87us/step - loss: nan - val_loss: nan\n",
      "Epoch 132/150\n",
      "800/800 [==============================] - 0s 92us/step - loss: nan - val_loss: nan\n",
      "Epoch 133/150\n",
      "800/800 [==============================] - 0s 92us/step - loss: nan - val_loss: nan\n",
      "Epoch 134/150\n",
      "800/800 [==============================] - 0s 89us/step - loss: nan - val_loss: nan\n",
      "Epoch 135/150\n",
      "800/800 [==============================] - 0s 88us/step - loss: nan - val_loss: nan\n",
      "Epoch 136/150\n",
      "800/800 [==============================] - 0s 92us/step - loss: nan - val_loss: nan\n",
      "Epoch 137/150\n",
      "800/800 [==============================] - 0s 96us/step - loss: nan - val_loss: nan\n",
      "Epoch 138/150\n",
      "800/800 [==============================] - 0s 88us/step - loss: nan - val_loss: nan\n",
      "Epoch 139/150\n",
      "800/800 [==============================] - 0s 87us/step - loss: nan - val_loss: nan\n",
      "Epoch 140/150\n",
      "800/800 [==============================] - 0s 84us/step - loss: nan - val_loss: nan\n",
      "Epoch 141/150\n",
      "800/800 [==============================] - 0s 93us/step - loss: nan - val_loss: nan\n",
      "Epoch 142/150\n",
      "800/800 [==============================] - 0s 85us/step - loss: nan - val_loss: nan\n",
      "Epoch 143/150\n",
      "800/800 [==============================] - 0s 85us/step - loss: nan - val_loss: nan\n",
      "Epoch 144/150\n",
      "800/800 [==============================] - 0s 82us/step - loss: nan - val_loss: nan\n",
      "Epoch 145/150\n",
      "800/800 [==============================] - 0s 89us/step - loss: nan - val_loss: nan\n",
      "Epoch 146/150\n",
      "800/800 [==============================] - 0s 84us/step - loss: nan - val_loss: nan\n",
      "Epoch 147/150\n",
      "800/800 [==============================] - 0s 83us/step - loss: nan - val_loss: nan\n",
      "Epoch 148/150\n",
      "800/800 [==============================] - 0s 80us/step - loss: nan - val_loss: nan\n",
      "Epoch 149/150\n",
      "800/800 [==============================] - 0s 82us/step - loss: nan - val_loss: nan\n",
      "Epoch 150/150\n",
      "800/800 [==============================] - 0s 81us/step - loss: nan - val_loss: nan\n"
     ]
    }
   ],
   "source": [
    "hist = vae.fit(x_train, x_train,\n",
    "               shuffle=True,\n",
    "               epochs=epochs,\n",
    "               batch_size=batch_size,\n",
    "               validation_data=(x_val, x_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
